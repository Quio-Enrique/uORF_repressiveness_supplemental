{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. RNA folding profiles in windows over transcriptome\n",
    "RNA folding on the scale of a whole transcriptome (to obtain profiles over uORFs and CDSes) was computationally intensive, and is thus documented in a separate iPython notebook here. Each transcriptome was split into 1000-transcript segments and folded in individual cluster jobs, before being re-collated.\n",
    "\n",
    "Secondary structure profiles were then compiled around AUGs throughout the transcript, further subdivided by how many uORFs were present in the transcript. Mean secondary structure ensemble folding energies were also determined over entire 5' leaders, uORFs and CDSes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating transcript 5' leader, CDS and 3' UTR lengths, number/position of uORFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"./data/\"\n",
    "ANNOTATIONS_DIR = \"./annotations/\"\n",
    "FOLDED_DIR = \"./folded/\"\n",
    "TO_FOLD_DIR = \"./to_fold/\"\n",
    "\n",
    "species_assembly = {\"mm\": \"GRCm38_ens\",\n",
    "                    \"hs\": \"GRCh37_ens\",\n",
    "                    \"dr\": \"Zv9_ens\"}\n",
    "stage_assembly = {\"HeLa\": \"GRCh37_ens\",\n",
    "                  \"mES\": \"GRCm38_ens\",\n",
    "                  \"Shield\": \"Zv9_ens\"}\n",
    "species_stage = {\"mm\": \"mES\",\n",
    "                 \"hs\": \"HeLa\",\n",
    "                 \"dr\": \"Shield\"}\n",
    "\n",
    "stages = [\"mES\", \"HeLa\", \"Shield\"]\n",
    "species = [\"mm\", \"hs\", \"dr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from Bio import SeqIO\n",
    "from pandas import DataFrame, Series\n",
    "from numpy import zeros\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lengths of 5' leaders, CDSes and 3' UTRs were calculated, along with the number of uORFs. These were stored in **\\_tlengths_uORFs.df** files for later reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INDEX = \"Transcript\"\n",
    "COLUMNS = [\"Gene\", \"Gene_Name\", \"Gene_Expression_FPKM\", \"UTR5_length\", \"UTR3_length\", \"CDS_length\",\n",
    "           \"num_uORFs\", \"uORFs_starts\", \"uORFs_ends\"]\n",
    "\n",
    "CONVERTERS = {i:literal_eval for i in (\"ORF_starts\", \"ORF_ends\", \"RPF_csvProfile\", \"CDS\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for s in species:\n",
    "    stage = species_stage[s]\n",
    "    df_main = DataFrame(columns=COLUMNS)\n",
    "    df_main.index.name = INDEX\n",
    "\n",
    "    # FILE ITERATOR FOR .trpedf\n",
    "    trpedf_file_iterator = pd.read_table(DATA_DIR + s + \"/\" + stage + \"_canonical.trpedf\",\n",
    "                                         converters=CONVERTERS, chunksize=1)\n",
    "\n",
    "    # ITERATE OVER .trpedf\n",
    "    for transcript in trpedf_file_iterator:\n",
    "\n",
    "        # Reads in data from each transcript\n",
    "        RPF_csvProfile = transcript[\"RPF_csvProfile\"][0]\n",
    "        ORF_starts = transcript[\"ORF_starts\"][0]\n",
    "        ORF_ends = transcript[\"ORF_ends\"][0]\n",
    "        if type(ORF_starts) is np.int64:      # corrects for single-entry\n",
    "            ORF_starts = (ORF_starts,)\n",
    "            ORF_ends = (ORF_ends,)\n",
    "        CDS = transcript[\"CDS\"][0]\n",
    "        ORFs = zip(ORF_starts, ORF_ends)\n",
    "        uORFs = [ORF for ORF in ORFs if ORF[0] < CDS[0]]  # uORFs defined as beginning before CDS\n",
    "\n",
    "        # Calculate and store values in main dictionary\n",
    "        entry = {}\n",
    "        for j in (\"Gene\", \"Gene_Name\", \"Gene_Expression_FPKM\"):\n",
    "            entry[j] = transcript[j][0]\n",
    "        entry[\"UTR5_length\"] = CDS[0]\n",
    "        entry[\"UTR3_length\"] = len(RPF_csvProfile) - CDS[1]\n",
    "        entry[\"CDS_length\"] = CDS[1] - CDS[0]\n",
    "        entry[\"num_uORFs\"] = len(uORFs)\n",
    "        entry[\"uORFs_starts\"] = [int(uORF[0]) for uORF in uORFs]\n",
    "        entry[\"uORFs_ends\"] = [int(uORF[1]) for uORF in uORFs]\n",
    "\n",
    "        df_main.loc[transcript[\"Transcript\"][0]] = Series(entry)\n",
    "    df_main.to_csv(DATA_DIR + s + \"/\" + stage + \"_tlengths_uORFs.df\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Folding RNAs in sliding windows\n",
    "The ViennaRNA Package (Version 2.1.7)  was compiled for python use (`./configure --with-python` followed by `make` and `make install`), and used to fold sliding windows of transcripts in the whole transcriptome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FASTA files were split into 1000-entry files to be folded in parallel on a computational cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for species, assembly in species_assembly.iteritems():\n",
    "    seqs = SeqIO.index(ANNOTATIONS_DIR + assembly + \"_gene_canonical.fasta\", \"fasta\")\n",
    "    length = len(seqs)\n",
    "    \n",
    "    seqs = SeqIO.parse(ANNOTATIONS_DIR + assembly + \"_gene_canonical.fasta\", \"fasta\")\n",
    "    num_files = length / 1000 + 1\n",
    "    for num in xrange(num_files):\n",
    "        with open(TO_FOLD_DIR + species + \"_\" + str(num) + \".fasta\", \"w+\") as f:\n",
    "            for i in xrange(1000):\n",
    "                record = seqs.next()\n",
    "                f.write(\">\" + record.id + \"\\n\" + str(record.seq) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following small python script was used to fold the split fasta files in parallel.\n",
    "\n",
    "This results in **\\_NN.fasta** files (e.g. **mm_25.fasta**) in the **./to_fold/** directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create fold_all.py from the following\n",
    "import sys\n",
    "import RNA\n",
    "\n",
    "from Bio import SeqIO\n",
    "from numpy import zeros\n",
    "from ast import literal_eval\n",
    "\n",
    "s = sys.argv[1]\n",
    "WINDOW = literal_eval(sys.argv[2])\n",
    "BLOCK = literal_eval(sys.argv[3])\n",
    "FASTA_FILE = s + \"_\" + str(BLOCK) + \".fasta\"\n",
    "SEQS = SeqIO.index(FASTA_FILE, \"fasta\")\n",
    "\n",
    "def fold_transcript(seq, WINDOW):\n",
    "    energies = zeros(len(seq) - WINDOW)\n",
    "    for i in range(len(seq) - WINDOW):\n",
    "        energies[i] = RNA.pf_fold(seq[i:i + WINDOW])[1]\n",
    "    return energies\n",
    "\n",
    "with open(\"_\".join([s, str(WINDOW), str(BLOCK)]) + \".df\", \"w+\") as f:\n",
    "    f.write(\"\\t\".join((\"Transcript\", \"ss_efe_profile\")) + \"\\n\")\n",
    "    for transcript in SEQS:\n",
    "        seq = str(SEQS[transcript].seq)\n",
    "        if len(seq) < 100: continue\n",
    "        f.write(transcript + \"\\t\" +  \",\".join([str(i) for i in fold_transcript(seq, WINDOW)]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following commands folds the split fasta files. The commands should be modified for specific cluster job management software (e.g. SLURM, LSF).\n",
    "\n",
    "The transcript sequences were folded in various window sizes (25, 30, 35, 40)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "SPECIES=\"mm\"\n",
    "for WINDOW in 25 30 35 40; do\n",
    "for BLOCK in {0..37}; do\n",
    "python fold_all.py ${SPECIES} ${WINDOW} ${BLOCK}\n",
    "done\n",
    "done\n",
    "\n",
    "SPECIES=\"hs\"\n",
    "for WINDOW in 25 30 35 40; do\n",
    "for BLOCK in {0..55}; do\n",
    "python fold_all.py ${SPECIES} ${WINDOW} ${BLOCK}\n",
    "done\n",
    "done\n",
    "\n",
    "SPECIES=\"dr\"\n",
    "for WINDOW in 25 30 35 40; do\n",
    "for BLOCK in {0..31}; do\n",
    "python fold_all.py ${SPECIES} ${WINDOW} ${BLOCK}\n",
    "done\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folded transcripts were collated into single files. Due to their size, these files are not included in the supplemental data, but may be similarly generated from the above code. The data needed for the data analyses ipython notebooks are extracted into their own files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "SPECIES=\"mm\"\n",
    "for WINDOW in 25 30 35 40; do\n",
    "printf 'Transcript\\tss_efe_profile\\n' > ./folded/${SPECIES}_${WINDOW}_ssefes.df\n",
    "cat ${SPECIES}_${WINDOW}_{0..37}.df | grep -v Transcript >> ./folded/${SPECIES}_${WINDOW}_ssefes.df\n",
    "done\n",
    "\n",
    "SPECIES=\"hs\"\n",
    "for WINDOW in 25 30 35 40; do\n",
    "printf 'Transcript\\tss_efe_profile\\n' > ./folded/${SPECIES}_${WINDOW}_ssefes.df\n",
    "cat ${SPECIES}_${WINDOW}_{0..55}.df | grep -v Transcript >> ./folded/${SPECIES}_${WINDOW}_ssefes.df\n",
    "done\n",
    "\n",
    "SPECIES=\"dr\"\n",
    "for WINDOW in 25 30 35 40; do\n",
    "printf 'Transcript\\tss_efe_profile\\n' > ./folded/${SPECIES}_${WINDOW}_ssefes.df\n",
    "cat ${SPECIES}_${WINDOW}_{0..31}.df | grep -v Transcript >> ./folded/${SPECIES}_${WINDOW}_ssefes.df\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiles around AUGs, subdivided by position in transcript and number of uORFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells collates secondary structure profiles over ORF starts (for Fig 1C), subdivided by their position in the transcript (5' leader, CDS start, within the CDS, or in the 3' UTR), as well as (for uORFs) by the number of uORFs within the transcript (for Fig S2B)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "windows = (25, 30, 35, 40)\n",
    "\n",
    "converter = {\"ss_efe_profile\": literal_eval}\n",
    "CONVERTERS = {i:literal_eval for i in (\"uORFs_starts\", \"uORFs_ends\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ATG_poss(string):\n",
    "    return [ATG.start() for ATG in re.finditer(\"ATG\", string)]\n",
    "\n",
    "def ATG_5CI3(ATG_positions, CDS):\n",
    "    return \"\".join(['C' if ATG_pos == CDS[0] else \\\n",
    "                    '5' if ATG_pos < CDS[0] else \\\n",
    "                    'I' if CDS[0] < ATG_pos < CDS[1] else \\\n",
    "                    '3' for ATG_pos in ATG_positions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for s in species:\n",
    "    stage = species_stage[s]\n",
    "    tlengths = pd.read_table(DATA_DIR + s + \"/\" + stage + \"_tlengths_uORFs.df\",\n",
    "                             sep=\"\\t\", index_col=0, converters=CONVERTERS)\n",
    "    FASTA_FILE = ANNOTATIONS_DIR + stage_assembly[stage] + \"_genes_canonical.fasta\"\n",
    "    SEQS = SeqIO.index(FASTA_FILE, \"fasta\")\n",
    "    \n",
    "    for window in windows:\n",
    "        data_iterator = pd.read_table(FOLDED_DIR + s + \"_\" + str(window) + \"_ssefes.df\",\n",
    "                                      sep=\"\\t\", index_col=0,\n",
    "                                      converters={\"ss_efe_profile\": literal_eval},\n",
    "                                      chunksize=100)\n",
    "\n",
    "        ATG_5CI3_profiles = {pos: Series(np.zeros(100), index=np.arange(-50, 50)) for pos in \"5CI3\"}\n",
    "        ATG_5CI3_count = {pos: 0 for pos in \"5CI3\"}\n",
    "        \n",
    "        uORF_profiles = {num: Series(np.zeros(100), index=np.arange(-50, 50)) for num in range(1, 5)}\n",
    "        uORF_count = {num: 0 for num in range(1, 5)}\n",
    "        \n",
    "        for data in data_iterator:\n",
    "            data = data[data.index.isin(tlengths.index)]\n",
    "            data[\"UTR5_length\"] = tlengths.UTR5_length[data.index]\n",
    "            data[\"UTR3_length\"] = tlengths.UTR3_length[data.index]\n",
    "            data[\"CDS_length\"] = tlengths.CDS_length[data.index]\n",
    "            data[\"fold_length\"] = data.ss_efe_profile.apply(len)\n",
    "            data[\"transcript_length\"] = data.UTR5_length + data.UTR3_length + data.CDS_length\n",
    "            data[\"CDS\"] = data.apply(lambda x: (x.UTR5_length, x.UTR5_length + x.CDS_length), axis=1)\n",
    "            data[\"seq\"] = Series({i:str(SEQS[i].seq) for i in data.index})\n",
    "            data[\"ATG_positions\"] = data.seq.apply(ATG_poss)\n",
    "            data[\"ATG_5CI3\"] = data.apply(lambda x: ATG_5CI3(x.ATG_positions, x.CDS), axis=1)\n",
    "            data[\"num_uORFs\"] = tlengths.num_uORFs[data.index]\n",
    "            \n",
    "            for _, entry in data.iterrows():\n",
    "                for pos, ATG_start in zip(entry.ATG_5CI3, entry.ATG_positions):\n",
    "                    if (ATG_start > 50) and (ATG_start + 50 + window < entry.transcript_length):\n",
    "                        slice_ATG = Series(np.array(entry.ss_efe_profile[ATG_start - 50: ATG_start + 50]),\n",
    "                                           index=np.arange(-50, 50))\n",
    "                        ATG_5CI3_profiles[pos] = ATG_5CI3_profiles[pos].add(slice_ATG)\n",
    "                        ATG_5CI3_count[pos] = ATG_5CI3_count[pos] + 1\n",
    "                \n",
    "                for num in range(1, 5):\n",
    "                    if entry.num_uORFs == 0: break\n",
    "                    if entry.num_uORFs <= num:\n",
    "                        uORF_starts = [uORF_start for pos, uORF_start in \\\n",
    "                                       zip(entry.ATG_5CI3, entry.ATG_positions) if pos == \"5\"]\n",
    "                        for uORF_start in uORF_starts:\n",
    "                            if (uORF_start > 50) and (uORF_start + 50 + window < entry.transcript_length):\n",
    "                                slice_uORF = Series(np.array(entry.ss_efe_profile[uORF_start - 50: uORF_start + 50]),\n",
    "                                                    index=np.arange(-50, 50))\n",
    "                                uORF_profiles[num] = uORF_profiles[num].add(slice_uORF)\n",
    "                                uORF_count[num] = uORF_count[num] + 1\n",
    "                        break\n",
    "                            \n",
    "        for pos in ATG_5CI3_profiles:\n",
    "            ATG_5CI3_profiles[pos] = ATG_5CI3_profiles[pos].divide(ATG_5CI3_count[pos])\n",
    "        for num in uORF_profiles:\n",
    "            uORF_profiles[num] = uORF_profiles[num].divide(uORF_count[num])\n",
    "        \n",
    "        ATG_5CI3_out = DATA_DIR + s + \"/\" + s + \"_\" + str(window) + \"_RNA_fold_ATG_profiles_by_pos\"\n",
    "        DataFrame(ATG_5CI3_profiles).to_csv(ATG_5CI3_out, sep=\"\\t\")\n",
    "        uORF_profiles_out = DATA_DIR + s + \"/\" + s + \"_\" + str(window) + \"_RNA_fold_uORF_profiles_by_num\"\n",
    "        DataFrame(uORF_profiles).to_csv(uORF_profiles_out, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate mean secondary structure EFE over 5' leader and CDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells calculate the mean secondary structure EFEs in various window sizes over the lengths of all 5' leaders and CDSes (for Fig S2G, also used in linear modelling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for s in species:\n",
    "    stage = species_stage[s]\n",
    "    tlengths = pd.read_table(DATA_DIR + s + \"/\" + stage + \"_tlengths_uORFs.df\",\n",
    "                             sep=\"\\t\", index_col=0, converters=CONVERTERS)\n",
    "    UTR5_mean_ssefe = {\"UTR5_mean_ssefe_\" + str(i):{} for i in [25, 30, 35, 40]}\n",
    "    CDS_mean_ssefe = {\"CDS_mean_ssefe_\" + str(i):{} for i in [25, 30, 35, 40]}\n",
    "    \n",
    "    for window in windows:\n",
    "        data_iterator = pd.read_table(FOLDED_DIR + s + \"_\" + str(window) + \"_ssefes.df\",\n",
    "                                      sep=\"\\t\", index_col=0,\n",
    "                                      converters={\"ss_efe_profile\": literal_eval}, chunksize=100)\n",
    "    \n",
    "        for data in data_iterator:\n",
    "            data = data[data.index.isin(tlengths.index)]\n",
    "            data[\"UTR5_length\"] = tlengths.UTR5_length[data.index].apply(int)\n",
    "            data[\"CDS_length\"] = tlengths.CDS_length[data.index].apply(int)\n",
    "            \n",
    "            chunk = data.apply(lambda x: None if (x.UTR5_length <= window) or (x.CDS_length <= 0) \\\n",
    "                               else np.mean(x.ss_efe_profile[:x.UTR5_length - window]),\n",
    "                               axis=1)\n",
    "            UTR5_mean_ssefe[\"UTR5_mean_ssefe_\" + str(window)].update(chunk.to_dict())\n",
    "            \n",
    "            chunk = data.apply(lambda x: None if (x.UTR5_length <= window) or (x.CDS_length <= 0) \\\n",
    "                               else np.mean(x.ss_efe_profile[x.UTR5_length: x.UTR5_length + x.CDS_length - window]),\n",
    "                               axis=1)\n",
    "            CDS_mean_ssefe[\"CDS_mean_ssefe_\" + str(window)].update(chunk.to_dict())\n",
    "            \n",
    "    UTR5_mean_ssefe = DataFrame(UTR5_mean_ssefe)\n",
    "    CDS_mean_ssefe = DataFrame(CDS_mean_ssefe)\n",
    "    gene_names = tlengths.Gene[tlengths.index.isin(UTR5_mean_ssefe.index)]\n",
    "    mean_ssefes = pd.concat([gene_names, UTR5_mean_ssefe, CDS_mean_ssefe], axis=1)\n",
    "    mean_ssefes[~np.isnan(mean_ssefes.UTR5_mean_ssefe_25)].to_csv(DATA_DIR + s + \"/\" + s + \"_mean_ssefes.df\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile SS_EFE profiles over CDS starts on a per-transcript basis\n",
    "For Fig S2B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for s in species:\n",
    "    stage = species_stage[s]\n",
    "    tlengths = pd.read_table(DATA_DIR + s + \"/\" + stage + \"_tlengths_uORFs.df\",\n",
    "                             sep=\"\\t\", index_col=0, converters=CONVERTERS)\n",
    "    \n",
    "    for window in windows:\n",
    "        data_iterator = pd.read_table(FOLDED_DIR + s + \"_\" + str(window) + \"_ssefes.df\",\n",
    "                                      sep=\"\\t\", index_col=0,\n",
    "                                      converters={\"ss_efe_profile\": literal_eval}, chunksize=500)\n",
    "        CDS_profiles = {}\n",
    "        \n",
    "        for data in data_iterator:\n",
    "            data = data[data.index.isin(tlengths.index)]\n",
    "            data[\"CDS_start\"] = tlengths.UTR5_length[data.index].map(int)\n",
    "            data[\"transcript_length\"] = (tlengths.UTR5_length[data.index] + \\\n",
    "                                         tlengths.UTR3_length[data.index] + \\\n",
    "                                         tlengths.CDS_length[data.index]).map(int)\n",
    "            \n",
    "            for transcript, entry in data.iterrows():\n",
    "                if (entry.CDS_start > 50) and (entry.CDS_start + 100 + window < entry.transcript_length):\n",
    "                    CDS_profiles[transcript] = Series(np.array(entry.ss_efe_profile[entry.CDS_start - 50: entry.CDS_start + 100]),\n",
    "                                                      index=np.arange(-50, 100))\n",
    "                    \n",
    "        DataFrame(CDS_profiles).to_csv(DATA_DIR + s + \"/\" + s + \"_\" + str(window) + \"_RNA_fold_CDS_start_profiles\", sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
