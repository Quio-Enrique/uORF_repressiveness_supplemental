{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Mapping ribosome profiling and RNA-seq data\n",
    "These steps collate information from transcriptome assemblies, RNA-seq and ribosome profiling raw data to produce \".trpedf\" files (details described below) which will be used in all subsequent data preprocessing steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Software Requirements\n",
    "A \\*nix-based system: Bowtie2, Tophat, Cufflinks, Bedtools\n",
    "\n",
    "Python 2.7 (with Numpy, Scipy, Pandas, ViennaRNA, Statsmodels, Biopython; everything but ViennaRNA can also be run on Windows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Data Source\n",
    "Ribosome profiling and RNA-seq data obtained from NCBI's Sequence Read Archive (SRA) by downloading the corresponding .SRA files. Genome and transcriptome annotations were obtained from Illumina iGenomes.\n",
    "\n",
    "<table>\n",
    "<tr><td>**Sample**</td><td>**Ribosome Profiling Data**</td><td>**RNA-Seq Data**</td><td>**Genome Assembly**</td><td>**Transcriptome**</td></tr>\n",
    "<tr><td>Human HeLa cells</td><td>SRR970587, SRR970588</td><td>SRR970592, SRR970593</td><td>GRCh37</td><td>Ensembl 70</td></tr>\n",
    "<tr><td>Mouse ES cells</td><td>SRR315616, SRR315617, SRR315618, SRR315619</td><td>SRR315595, SRR315596</td><td>GRCm38</td><td>Ensembl 70</td></tr>\n",
    "<tr><td>Zebrafish Shield stage</td><td>SRR836196</td><td>SRR2047225</td><td>Zv9</td><td>Ensembl 70</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SRA files were converted to fastq files and clipped of 3' ligation adapter sequences \"CTGTAGGCACCATCAAT\", retaining reads >= 25 nucleotides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping Ribosome Profiling Data\n",
    "Ribosome profiling reads were first depleted of abundent sequences such as rRNA using Bowtie2. Abundant sequences were compiled from the AbundantSequences directory from Illumina iGenomes, and built into a Bowtie2 index. Additional manually-curated rRNA sequences for zebrafish were used, and are included in the supplementary data files.\n",
    "\n",
    "Example using Mouse ES cell ribosome profiling data below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat *.fa > ./annotations/GRCm38_Abundant.fa\n",
    "bowtie2-build ./annotations/GRCm38_Abundant.fa GRCm38_Abundant\n",
    "\n",
    "OPTIONS=\"-N 0 -L 23 --norc\"\n",
    "bowtie2 $OPTIONS --un ribo_mES_sub_abund.fastq -x GRCm38_Abundant -U ribo_mES.fastq -S /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remaining reads were mapped to the Ensembl 70 transcriptome using Tophat, allowing no indels, junctions only from gene annotations, max 10 multihits, with multihit pre-filtering. Use the .gtf files and Bowtie2 indices (\"genome\") from the corresponding iGenomes compilation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "OPTIONS=\"--max-insertion-length 0 --max-deletion-length 0\\\n",
    "--no-novel-juncs -g 10 --prefilter-multihits\\\n",
    "--library-type fr-secondstrand\"\n",
    "tophat -o ribo_mES $OPTIONS -G genes.gtf genome ribo_mES_sub_abund.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping RNA-Seq Data\n",
    "RNA-seq reads (when libraries were constructed by 3' ligation) were mapped by Tophat using the following parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "OPTIONS=\"--no-novel-juncs --library-type=fr-secondstrand\"\n",
    "tophat -o mRNA_mES $OPTIONS -G genes.gtf genome mRNA_mES.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantification of RNA-seq data was done using Cufflinks; accepted_hits.bam is from the Tophat output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "OPTIONS=\"-b genome.fa --multi-read-correct --library-type=fr-secondstrand\"\n",
    "cufflinks ${OPTIONS} -o cuffdiff/ -G genes.gtf accepted_hits.bam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assembling Canonical Transcriptome\n",
    "To generate a list of transcripts that only use one \"canonical\" transcript isoform per gene, ensGtp tables for each vertebrate species were retrieved from the UCSC genome browser. BED files were generated from the refFlat files in the iGenomes compilation, using the following awk script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ASSEMBLY=\"GRCm38_ens\"\n",
    "# Save following script as file [refFlat_to_bed12.awk]\n",
    "# run as 'refFlat_to_bed12.awk refFlat.txt > ./annotations/$ASSEMBLY_genes.bed'\n",
    "\n",
    "#!/bin/awk -f\n",
    "BEGIN  {FS=\"\\t\"; OFS=\"\\t\"}\n",
    "{   blockSizes=\"\";\n",
    "    blockStarts=\"\";\n",
    "    split($10,exonStarts,\",\");\n",
    "    split($11,exonEnds,\",\");\n",
    "    \n",
    "    for (i=1; i<=$9; i++)\n",
    "    {   blockSizes=blockSizes exonEnds[i]-exonStarts[i] \",\";\n",
    "    blockStarts=blockStarts exonStarts[i]-$5 \",\";\n",
    "    }\n",
    "    blockSizes = substr(blockSizes,1,length(blockSizes)-1);\n",
    "    blockStarts = substr(blockStarts,1,length(blockStarts)-1);\n",
    "    print $3,$5,$6,$2,0,$4,$7,$8,\"0,0,0\",$9,blockSizes,blockStarts;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Canonical transcriptome contain one transcript per gene: the transcript with the longest CDS, then longest 5' UTR, then longest transcript length.\n",
    "\n",
    "With the BED file and ensGtp file in the same directory, the following python script was run to generate \"\\$ASSEMBLY_genes_canonical.bed\", which is the transcript subset of \\$ASSEMBLY_genes.bed with one transcript per gene.\n",
    "\n",
    "Upload the file to UCSC as a custom track and use it to obtain the corresponding fasta file. Alternatively, the transcriptome fasta file can be obtained from a local whole genome fasta file using bedtools getfasta (a.k.a. getFastaFromBed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ANNOTATIONS_DIR = \"./annotations/\"\n",
    "DATA_DIR = \"./data/\"\n",
    "ASSEMBLY = \"GRCm38_ens\"\n",
    "\n",
    "def transcript_position(exons, c_intron_lengths, genomic_pos):\n",
    "    for exon, c_intron_length in zip(exons, c_intron_lengths):\n",
    "        if genomic_pos >= exon[0] and genomic_pos <= exon[1]:\n",
    "            return genomic_pos - exons[0][0] - c_intron_length\n",
    "\n",
    "def read_Gtp_file(Gtp_file):\n",
    "    transcript_to_gene = {}\n",
    "    gene_to_transcript = {}\n",
    "    with open(Gtp_file, \"r+\") as f:\n",
    "        for line in f:\n",
    "            entry = line.strip().split(\"\\t\")\n",
    "            transcript_to_gene[entry[1]] = entry[0]\n",
    "            gene_to_transcript.setdefault(entry[0], []).append(entry[1])\n",
    "    return transcript_to_gene, gene_to_transcript\n",
    "        \n",
    "#%% OPEN FILES\n",
    "\n",
    "with open(ANNOTATIONS_DIR + ASSEMBLY + \"_genes.bed\", \"r+\") as in_bed, \\\n",
    "open(ANNOTATIONS_DIR + ASSEMBLY + \"_genes_canonical.bed\", \"w+\") as out_bed:\n",
    "\n",
    "    #%% READ GTP FILE\n",
    "    transcript_to_gene, gene_to_transcript = read_Gtp_file(ANNOTATIONS_DIR + ASSEMBLY + \"Gtp\")\n",
    "    \n",
    "    #%% READ BED FILES\n",
    "    bed_store = {}\n",
    "    for line in in_bed:\n",
    "        _, chromStart, chromEnd, name, \\\n",
    "        _, strand, thickStart, thickEnd, \\\n",
    "        _, blockCount, blockSizes, blockStarts = line.split(\"\\t\")\n",
    "        if name not in transcript_to_gene:\n",
    "            continue\n",
    "\n",
    "        #%% CONVERT ENTRY TO INTEGERS\n",
    "        chromStart, chromEnd, thickStart, thickEnd, blockCount = map(int,\n",
    "                                                                     (chromStart, chromEnd,\n",
    "                                                                      thickStart, thickEnd, blockCount))\n",
    "        blockSizes = map(int, blockSizes.split(\",\"))\n",
    "        blockStarts = map(int, blockStarts.split(\",\"))\n",
    "\n",
    "        #%% SECONDARY DATA FOR CALCULATIONS\n",
    "        intron_lengths = [(blockStarts[i+1]-blockStarts[i]-blockSizes[i]) for i in xrange(blockCount-1)]\n",
    "        c_intron_lengths = [sum(intron_lengths[:i]) for i in xrange(blockCount)]\n",
    "        exons = [[i[0] + chromStart, sum(i) + chromStart] for i in zip(blockStarts, blockSizes)]\n",
    "        plus_strand = (strand == \"+\")\n",
    "\n",
    "        #%% CALCULATE LENGTHS: TRANSCRIPT, 5'LEADER, CDS, 3'UTR\n",
    "        transcript_length = sum(blockSizes)\n",
    "        if plus_strand:\n",
    "            UTR5_length = abs(transcript_position(exons, c_intron_lengths, thickStart)\\\n",
    "                              - transcript_position(exons, c_intron_lengths, chromStart))\n",
    "            UTR3_length = abs(transcript_position(exons, c_intron_lengths, chromEnd)\\\n",
    "                              - transcript_position(exons, c_intron_lengths, thickEnd))\n",
    "        else:\n",
    "            UTR5_length = abs(transcript_position(exons, c_intron_lengths, chromEnd)\\\n",
    "                              - transcript_position(exons, c_intron_lengths, thickEnd))\n",
    "            UTR3_length = abs(transcript_position(exons, c_intron_lengths, thickStart)\\\n",
    "                              - transcript_position(exons, c_intron_lengths, chromStart))\n",
    "        CDS_length = abs(transcript_position(exons, c_intron_lengths, thickEnd)\\\n",
    "                         - transcript_position(exons, c_intron_lengths, thickStart))\n",
    "        bed_store[name] = [line, CDS_length, UTR5_length, transcript_length]\n",
    "\n",
    "    #%% FIND TRANSCRIPT WITH LONGEST CDS, THEN LONGEST 5' LEADER, THEN LONGEST TRANSCRIPT LENGTH, PER GENE, OUTPUT\n",
    "    for gene in gene_to_transcript:\n",
    "        try:\n",
    "            canonical_transcript = sorted([[transcript, bed_store[transcript][1],\n",
    "                                            bed_store[transcript][2],\n",
    "                                            bed_store[transcript][3]] \\\n",
    "                                           for transcript in gene_to_transcript[gene] \\\n",
    "                                           if transcript in bed_store], key=lambda i: (i[1], i[2], i[3]))[-1][0]\n",
    "        except IndexError:\n",
    "            continue\n",
    "        out_bed.write(bed_store[canonical_transcript][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrating ribosome profiling, RNA-seq data in transcript coordinates\n",
    "For data analysis, a custom file-format is used that integrates RNA-seq and ribosome profiling data in the context of a defined transcriptome.\n",
    "\n",
    "Ribosome profiling data first needs to be assembled at nucleotide resolution. Note that the offsets correspond to P-site, rather than A-site.\n",
    "\n",
    "Use either of the following awk scripts as part of the conversion of .bam files (accepted_hits.bam from Tophat)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create file as bed12_to_bedpoint_mammal.awk, for use with human and mouse ribosome profiling data\n",
    "\n",
    "#!/bin/awk -f\n",
    "BEGIN {OFS=\"\\t\"}\n",
    "\n",
    "{if ($10 != 1){\n",
    "    split($11,a,\",\");\\\n",
    "    split($12,b,\",\");\\\n",
    "    len=0;\\\n",
    "    for (i in a){len+= a[i]}\n",
    "}\n",
    "else\n",
    "    {len=$11}\n",
    "\n",
    "out=(len>=29 && len<=35);\\\n",
    "strand=$6;\\\n",
    "if (out){\n",
    "if(strand==\"+\"){\n",
    "         if(len == 29) offset = 12;\\\n",
    "    else if(len == 30) offset = 12;\\\n",
    "    else if(len == 31) offset = 13;\\\n",
    "    else if(len == 32) offset = 13;\\\n",
    "    else if(len == 33) offset = 13;\\\n",
    "    else if(len == 34) offset = 14;\\\n",
    "    else if(len == 35) offset = 14;\\\n",
    "    }\n",
    "else{    if(len == 29) offset = 16;\\\n",
    "    else if(len == 30) offset = 17;\\\n",
    "    else if(len == 31) offset = 17;\\\n",
    "    else if(len == 32) offset = 18;\\\n",
    "    else if(len == 33) offset = 19;\\\n",
    "    else if(len == 34) offset = 19;\\\n",
    "    else if(len == 35) offset = 20;\\\n",
    "    }\n",
    "}\n",
    "\n",
    "if(out && ($10 == 1)){print $1, $2+offset, $2+offset+1, $4, $5, $6}\n",
    "else if(out){\n",
    "    for (i in a){\n",
    "        if (offset <= a[i] && offset > 0){print $1, $2+offset+b[i], $2+offset+b[i]+1, $4, $5, $6}\n",
    "        offset -= a[i];\\\n",
    "    }\n",
    "}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create file as bed12_to_bedpoint_zf.awk, for use with zebrafish ribosome profiling data\n",
    "\n",
    "#!/bin/awk -f\n",
    "BEGIN {OFS=\"\\t\"}\n",
    "\n",
    "{if ($10 != 1){\n",
    "    split($11,a,\",\");\\\n",
    "    split($12,b,\",\");\\\n",
    "    len=0;\\\n",
    "    for (i in a){len+= a[i]}\n",
    "}\n",
    "else\n",
    "    {len=$11}\n",
    "\n",
    "out=(len>=27 && len<=32);\\\n",
    "strand=$6;\\\n",
    "if (out){\n",
    "if(strand==\"+\"){\n",
    "         if(len == 27) offset = 11;\\\n",
    "    else if(len == 28) offset = 11;\\\n",
    "    else if(len == 29) offset = 12;\\\n",
    "    else if(len == 30) offset = 12;\\\n",
    "    else if(len == 31) offset = 12;\\\n",
    "    else if(len == 32) offset = 13;\\\n",
    "    }\n",
    "else{    if(len == 27) offset = 15;\\\n",
    "    else if(len == 28) offset = 16;\\\n",
    "    else if(len == 29) offset = 16;\\\n",
    "    else if(len == 30) offset = 17;\\\n",
    "    else if(len == 31) offset = 18;\\\n",
    "    else if(len == 32) offset = 18;\\\n",
    "   }\n",
    "}\n",
    "\n",
    "if(out && ($10 == 1)){print $1, $2+offset, $2+offset+1, $4, $5, $6}\n",
    "else if(out){\n",
    "    for (i in a){\n",
    "        if (offset <= a[i] && offset > 0){print $1, $2+offset+b[i], $2+offset+b[i]+1, $4, $5, $6}\n",
    "    offset -= a[i];\\\n",
    "    }\n",
    "}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the following commands (from BedTools) generates the \".in\" files that will be used for creating the \".trpedf\" files in subsequent analyses, as well as strand-specific bedgraph files (can be converted to binary .bw files using bedgraphToBigWig from UCSC, for easy viewing in most genome browsers). \".bg.bed\" files may be deleted following execution of these commands. The respective \"ChromInfo.txt\" files can be found in the iGenomes compilations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "ASSEMBLY=\"GRCm38_ens\"\n",
    "bamToBed -bed12 -i accepted_hits.bam | bed12_to_bedpoint_mammal.awk |\\\n",
    "    tee >(genomeCoverageBed -bg -i stdin -g ChromInfo.txt -strand + > mES_fwd.bedgraph) \\\n",
    "        >(genomeCoverageBed -bg -i stdin -g ChromInfo.txt -strand - > mES_rev.bedgraph) \\\n",
    "        >/dev/null\n",
    "\n",
    "awk 'BEGIN{FS=\"\\t\";OFS=\"\\t\"}{print $1,$2,$3,\".\",$4,\"+\"}' mES_fwd.bedgraph > mES_fwd.bg.bed\n",
    "awk 'BEGIN{FS=\"\\t\";OFS=\"\\t\"}{print $1,$2,$3,\".\",-$4,\"-\"}' mES_rev.bedgraph > mES_rev.bg.bed\n",
    "\n",
    "cat mES_fwd.bg.bed mES_rev.bg.bed | sort -k1,1 -k2,2n > mES.bg.bed\n",
    "intersectBed -wa -wb -s -split -a $ASSEMBLY_genes_canonical.bed -b mES_rev.bg.bed | \\\n",
    "awk 'BEGIN{FS=\"\\t\"; OFS=\"\\t\"}\\\n",
    "    {if ($4==curr) print $14,$15,$17;\\\n",
    "    else {print $1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11,$12; print $14,$15,$17; curr=$4}}'\\\n",
    "> mES_canonical.in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following python script integrates mRNA expression data from cufflinks (genes.fpkm_tracking files from the cufflinks output), ribosome profiling data from \".in\" files, and sequence data (from genes_canonical.fasta, derived from genes_canonical.bed; to define all ORFs).\n",
    "\n",
    "gene_canonical.fasta file can be generated from genes_canonical.bed either by uploading the .bed file to UCSC and downloading the fasta, or by using Bedtools getfasta.\n",
    "\n",
    "Data was organized in a tab-separated custom ASCII file format (.trpedf) for subsequent processing.\n",
    "(N.B. trpedf ~ **t**ranscript **r**ibosome **p**rofile **e**xtended, **D**ata**F**rame compatible)\n",
    "\n",
    "<table>\n",
    "<tr><td>**Column**</td><td>**Description**</td></tr>\n",
    "<tr><td>Transcript</td><td>Transcript ID</td></tr>\n",
    "<tr><td>Gene</td><td>Gene ID</td></tr>\n",
    "<tr><td>Gene_Name</td><td>Gene Name</td></tr>\n",
    "<tr><td>Gene_Expression_FPKM</td><td>Expression at gene level (from corresponding RNA-seq data; Tophat + Cufflinks)</td></tr>\n",
    "<tr><td>ORF_starts</td><td>ORF starts (comma-separated values in transcript coordinates, 0-based)</td></tr>\n",
    "<tr><td>ORF_ends</td><td>ORF ends (as above)</td></tr>\n",
    "<tr><td>RPF_csvProfile</td><td>Ribosome profiling reads at nucleotide resolution in transcript coordinates, for length of transcript, comma-separated values</td></tr>\n",
    "<tr><td>CDS</td><td>Annotated CDS</td></tr>\n",
    "</table>\n",
    "\n",
    "\".in\" files may be deleted following execution of these commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ASSEMBLY = \"GRCm38_ens\"\n",
    "stage = \"mES\"\n",
    "\n",
    "from Bio import SeqIO\n",
    "from ast import literal_eval\n",
    "import hmm_for_RPF_Seq as h\n",
    "\n",
    "def read_genes_tracking_file(tracking_file, stages):\n",
    "    expected_line_length = 9 + 4 * len(stages)\n",
    "    ensg_expression = {stage:{} for stage in stages}\n",
    "    ensg_name = {}\n",
    "    with open(tracking_file, \"r+\") as f:\n",
    "        for line in f:\n",
    "            entry = line.strip().split(\"\\t\")\n",
    "            if entry[0] == \"tracking_id\" or len(entry) != expected_line_length: continue\n",
    "            for i, stage in enumerate(stages):\n",
    "                expression = 4 * i + 9\n",
    "                status = 4 * i + 12\n",
    "                if entry[status] != \"OK\": continue\n",
    "                ensg_expression[stage][entry[0]] = float(entry[(expression)])\n",
    "            ensg_name[entry[0]] = entry[4]\n",
    "        return ensg_expression, ensg_name\n",
    "\n",
    "def read_Gtp_file(Gtp_file):\n",
    "    transcript_to_gene = {}\n",
    "    gene_to_transcript = {}\n",
    "    with open(Gtp_file, \"r+\") as f:\n",
    "        for line in f:\n",
    "            entry = line.strip().split(\"\\t\")\n",
    "            transcript_to_gene[entry[1]] = entry[0]\n",
    "            gene_to_transcript.setdefault(entry[0], []).append(entry[1])\n",
    "    return transcript_to_gene, gene_to_transcript\n",
    "\n",
    "def csv(list):\n",
    "    return \",\".join(map(str, list))\n",
    "\n",
    "def tsv_line(*list):\n",
    "    return \"\\t\".join(map(str, list)) + \"\\n\"\n",
    "\n",
    "def ORF_start_end(seq):\n",
    "    ORF_list = []\n",
    "    seq_len = len(seq)\n",
    "    for frame in xrange(3):\n",
    "        trans = str(seq[frame:].translate(1))\n",
    "        trans_len = len(trans)\n",
    "        aa_start, aa_end = [0 for i in xrange(2)]\n",
    "        while aa_start < trans_len:\n",
    "            aa_start = trans.find(\"M\", aa_start)\n",
    "            if aa_start == -1:\n",
    "                break\n",
    "            aa_end = trans.find(\"*\", aa_start)\n",
    "            ORF_start = frame + aa_start * 3\n",
    "            ORF_end = frame + aa_end * 3 + 3\n",
    "            if aa_end == -1:\n",
    "                ORF_end = seq_len\n",
    "            ORF_list.append((ORF_start, ORF_end))\n",
    "            aa_start = aa_start + 1\n",
    "    return zip(*tuple(sorted(ORF_list)))\n",
    "\n",
    "def transcript_position(exons, c_intron_lengths, genomic_pos):\n",
    "    for exon, c_intron_length in zip(exons, c_intron_lengths):\n",
    "        if genomic_pos >= exon[0] and genomic_pos <= exon[1]:\n",
    "            return genomic_pos - exons[0][0] - c_intron_length\n",
    "    return\n",
    "\n",
    "def parse_in_file(f, prev_entry_pos):\n",
    "    f.seek(prev_entry_pos)\n",
    "    while 1:\n",
    "        line = f.readline()\n",
    "        entry = line.split()\n",
    "        if len(entry) != 3:\n",
    "            try:\n",
    "                if thick_start == thick_end: transcript_CDS = [0,0]\n",
    "                else:\n",
    "                    # assume strand is \"+\" first\n",
    "                    transcript_CDS = [transcript_position(exons, c_intron_lengths, thick_start),\n",
    "                                      transcript_position(exons, c_intron_lengths, thick_end)]\n",
    "                    if strand == \"-\":\n",
    "                        transcript_bedgraph.reverse()\n",
    "                        transcript_CDS[0], transcript_CDS[1] = (transcript_length - transcript_CDS[1],\n",
    "                                                                transcript_length - transcript_CDS[0])\n",
    "                return transcript_ID, transcript_CDS, transcript_bedgraph, prev_entry_pos\n",
    "            except UnboundLocalError:\n",
    "                pass\n",
    "            transcript_ID, strand = (entry[3], entry[5])\n",
    "            transcript_start, thick_start, thick_end, block_count = map(int, (entry[1], entry[6], entry[7], entry[9]))\n",
    "\n",
    "            block_sizes = literal_eval(entry[10])\n",
    "            genome_block_starts = literal_eval(entry[11])\n",
    "            \n",
    "            transcript_length = sum(block_sizes)\n",
    "            transcript_bedgraph = [0] * transcript_length\n",
    "            \n",
    "            #introns and exons below in *GENOMIC* coordinates (i.e. not strand-specific)\n",
    "            intron_lengths = [(genome_block_starts[i+1]-genome_block_starts[i]-block_sizes[i]) for i in xrange(block_count-1)]\n",
    "            \n",
    "            c_intron_lengths = [sum(intron_lengths[:i]) for i in xrange(block_count)]\n",
    "            exons = [[i[0], sum(i)] for i in zip(genome_block_starts, block_sizes)]\n",
    "            prev_entry = entry\n",
    "        else:\n",
    "            prev_entry_pos = f.tell()\n",
    "            transcript_pos = transcript_position(exons, c_intron_lengths, int(entry[1]))\n",
    "            if transcript_pos != None:\n",
    "                for i in xrange(int(entry[1])-int(entry[0])):\n",
    "                    if transcript_pos + i < transcript_length:\n",
    "                        transcript_bedgraph[transcript_pos + i] = abs(int(entry[2]))\n",
    "\n",
    "#%% Files, Stages\n",
    "\n",
    "ensg_expression, ensg_name = read_genes_tracking_file(DATA_DIR + stage + \"_genes.fpkm_tracking\", stages)\n",
    "seqs = SeqIO.index(ANNOTATIONS_DIR + ASSEMBLY + \"_genes_canonical.fasta\", \"fasta\")\n",
    "enst_to_ensg, ensg_to_enst = read_Gtp_file(ANNOTATIONS_DIR + ASSEMBLY + \"Gtp\")\n",
    "\n",
    "in_file = stage + \".in\"\n",
    "trpedf_file = DATA_DIR + stage + \"_canonical.trpedf\"\n",
    "\n",
    "#%% DEFINE ORFs in seqs\n",
    "ORF_starts_ends = {}\n",
    "for seq in seqs:\n",
    "    ORF_starts_ends[seq] = ORF_start_end(seqs[seq].seq)\n",
    "\n",
    "with open(in_file, 'rb+') as f, open(trpedf_file, 'w+') as out:\n",
    "    out.write(tsv_line(\"Transcript\", \"Gene\", \"Gene_Name\", \"Gene_Expression_FPKM\",\n",
    "                       \"ORF_starts\", \"ORF_ends\", \"RPF_csvProfile\", \"CDS\"))\n",
    "    prev_entry_pos = 0\n",
    "    while 1:\n",
    "        try:\n",
    "            ID,transcript_CDS, transcript_bedgraph, prev_entry_pos = parse_in_file(f, prev_entry_pos)\n",
    "        except IndexError:\n",
    "            break\n",
    "        try:\n",
    "            expression = ensg_expression[stage][enst_to_ensg[ID]]\n",
    "        except KeyError:\n",
    "            continue\n",
    "        try:\n",
    "            name = ensg_name[enst_to_ensg[ID]]\n",
    "        except KeyError:\n",
    "            name = enst_to_ensg[ID]\n",
    "        if len(ORF_starts_ends[ID]) == 0: continue\n",
    "        out.write(tsv_line(ID, enst_to_ensg[ID], name, expression,\n",
    "                           csv(ORF_starts_ends[ID][0]),\n",
    "                           csv(ORF_starts_ends[ID][1]),\n",
    "                           csv(transcript_bedgraph),\n",
    "                           csv(transcript_CDS)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
